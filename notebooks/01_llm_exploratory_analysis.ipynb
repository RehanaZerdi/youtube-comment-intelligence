{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**YouTube Comment Intelligence System – Data Preparation & Batching**"
      ],
      "metadata": {
        "id": "d6Vb28wh4uw6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUHbaYaYSlKo",
        "outputId": "7aa496e9-22e8-47c5-f884-9e73102892cb",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.4.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.8.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.4.1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.12/dist-packages (0.14.12)\n",
            "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.3)\n",
            "Requirement already satisfied: llama-index-core<0.15.0,>=0.14.12 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.14.12)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.9.4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.6.13)\n",
            "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (3.13.3)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (0.22.1)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2.12.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (3.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2.4.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (4.5.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2.12.3)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.12->llama-index) (2.0.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.12->llama-index) (1.17.3)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (2.14.0)\n",
            "Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.12/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.5)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.3.3)\n",
            "Requirement already satisfied: pypdf<7,>=6.1.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.6.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (2025.11.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.22.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.15.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.12->llama-index) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.4.2)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.54 in /usr/local/lib/python3.12/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.26.2)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.12->llama-index) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.12->llama-index) (3.0.3)\n",
            "Requirement already satisfied: llama-index-llms-groq in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-groq) (0.14.12)\n",
            "Requirement already satisfied: llama-index-llms-openai-like<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-groq) (0.5.3)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (3.13.3)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (0.22.1)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (2.12.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (3.6.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (2.4.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (4.5.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (2.12.3)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (2.0.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (1.17.3)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.6.13)\n",
            "Requirement already satisfied: transformers<5,>=4.37.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (4.57.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (1.22.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (1.15.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (3.1.6)\n",
            "Requirement already satisfied: openai<3,>=1.108.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-openai<0.7,>=0.6.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (2.14.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (2025.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (3.20.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (25.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.7.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (3.26.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (1.2.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3,>=1.108.1->llama-index-llms-openai<0.7,>=0.6.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3,>=1.108.1->llama-index-llms-openai<0.7,>=0.6.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3,>=1.108.1->llama-index-llms-openai<0.7,>=0.6.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-groq) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# Core data handling\n",
        "!pip install -U pandas numpy openpyxl\n",
        "\n",
        "# NLP utilities\n",
        "!pip install -U scikit-learn sentence-transformers\n",
        "\n",
        "# LlamaIndex core\n",
        "!pip install -U llama-index\n",
        "\n",
        "# NEW & OFFICIAL Groq integration for LlamaIndex\n",
        "!pip install -U llama-index-llms-groq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Core Data Processing (pandas, numpy, openpyxl)**\n",
        "These libraries are used to load and process the Excel-based YouTube comment dataset. They handle tasks such as reading .xlsx files, cleaning missing or empty values, extracting the comment column, converting data into Python lists, and computing basic statistics like average comment length and word counts.\n",
        "\n",
        "###**Semantic NLP and Clustering (sentence-transformers, scikit-learn)**\n",
        "These tools enable semantic understanding of comments. Sentence Transformers convert each comment into a numerical embedding that captures its meaning, while scikit-learn provides clustering algorithms such as K-Means to group similar comments together and discover hidden topics. This allows the system to work in an unsupervised way without requiring labeled data.\n",
        "\n",
        "###**LLM-Powered Summarization (llama-index, llama-index-llms-google-genai)**\n",
        "  LlamaIndex provides the framework for organizing and summarizing large volumes of text using hierarchical tree-based methods. The Google GenAI integration connects Gemini models to this framework, allowing the system to generate high-quality summaries and insights from batches of comments while staying within model context limits."
      ],
      "metadata": {
        "id": "FroOv5HH_bP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "\n",
        "from llama_index.core import Document\n",
        "from llama_index.core.indices.tree import TreeIndex\n",
        "from llama_index.core import Settings\n",
        "\n",
        "import google.generativeai as genai\n"
      ],
      "metadata": {
        "id": "yHh7TlcLSrT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dec4696-849c-4686-d396-069e6d1b6e4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  loader.exec_module(module)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Required Libraries**\n",
        "\n",
        "This cell imports all the Python libraries needed for our YouTube Comment Insight System.\n",
        "\n",
        "#### **Data Processing**\n",
        "- **pandas** → for loading and manipulating Excel and CSV files  \n",
        "- **numpy** → for numerical operations and array handling  \n",
        "- **re** → for text cleaning using regular expressions  \n",
        "- **random** → for sampling and experimentation  \n",
        "\n",
        "#### **LLM & Knowledge Indexing**\n",
        "- **llama_index** → to convert comments into documents and build a tree-based knowledge index  \n",
        "- **Document** → represents each comment as a document  \n",
        "- **TreeIndex** → organizes documents in a hierarchical structure for efficient querying  \n",
        "- **Settings** → controls model and embedding configurations  \n",
        "\n",
        "#### **Google Generative AI**\n",
        "- **google.generativeai** → connects our system with Google Gemini models for intelligent summarization and insights\n"
      ],
      "metadata": {
        "id": "DOG7Ud9TGjkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your Excel file manually in Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get uploaded file name\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Load Excel file\n",
        "df=pd.read_excel(file_name)\n",
        "\n",
        "# Keep only the comment column\n",
        "COMMENT_COLUMN = \"Comment\"\n",
        "\n",
        "# Keep only the comment column\n",
        "df = df[[COMMENT_COLUMN]]\n",
        "\n",
        "# Drop real NaN values\n",
        "df = df.dropna()\n",
        "\n",
        "# Convert to string (only after NaNs removed)\n",
        "df[COMMENT_COLUMN] = df[COMMENT_COLUMN].astype(str)\n",
        "\n",
        "# Remove truly empty rows (but NOT emojis, slang, mixed language, etc)\n",
        "df = df[df[COMMENT_COLUMN].str.strip() != \"\"]\n",
        "\n",
        "print(\"Total comments available:\", len(df))\n",
        "print(\"\\nSample raw comments:\")\n",
        "for c in df[COMMENT_COLUMN].head(5):\n",
        "    print(\"-\", c)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "collapsed": true,
        "id": "fV4HS1doU5bv",
        "outputId": "2ce46624-6981-4464-dad9-0d2ea1fc2196"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a63ac61f-37ce-43eb-bdd8-c8f63f763eb7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a63ac61f-37ce-43eb-bdd8-c8f63f763eb7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving youtube_comments (1).xlsx to youtube_comments (1).xlsx\n",
            "Total comments available: 1072\n",
            "\n",
            "Sample raw comments:\n",
            "- Honest feedback I want to share regarding @CodeWithHarry. I have completed your reactjs course long back, 2 front-end project and 3rd one complete mern stack. I had gone through multiple tutorials, but when I did complete your free tutorial I never looked at any other course. I started building products my own, in interview I was asked to write code using reactjs and currently I am pursuing my masters at IIT that too in Data Science yet I have taken your course. I truly believe your knowledge, and more than that the way you deliver the content. I was last in c programming exam back in first year of bachelor's but by completing the engineering I had done multiple internships cracked most of companies then I'm into iit now. There is a huge hand of yours behind my success. Thankyou Harry bhaiyya and just a suggestion I would request ki mathematics bhi depth mein sikhaye for every algorithm and even using cloud for deployment covering mlops using cicd pipeline and everything including generative ai, advanced rag, agentic ai, voice ai agents and so. Yet I'm super excited regarding your course how it goes. Thankyou once again bhaiyya for bringing such a wonderful course. I have lots of hopes from this course. I truly believe you bhaiyya.\n",
            "- #HarryBhai​ ❤\n",
            "- Honestly, Harry bhai, aise roadmap video ki expectation nahi thi aapse. AI ek fast-growing skill hai aur abhi full boom pe hai, to har ek topic ko bahut deep jaake expensive books kharid ke padhna zaroori nahi hai. Aaj-kal almost har topic YouTube aur internet pe free aur achhe visual explanations ke saath available hai.\n",
            "Isliye yeh video thoda under-researched aur unnecessary lag raha hai.\n",
            "- Here is anyone who purchased this course, please your feedback 🙏😢\n",
            "- Can I learn at 14 years\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Excel Upload & Cleaning**\n",
        "**df[[COMMENT_COLUMN]]** → Keeps only the YouTube comment text and removes all other columns\n",
        "\n",
        "**dropna()** → Removes only real missing values without touching meaningful text\n",
        "\n",
        "**astype(str**) → Converts all remaining comments into text format for LLM input\n",
        "\n",
        "**str.strip() != \"\"** → Removes truly empty rows while preserving emojis, slang, and mixed language\n",
        "\n",
        "**len(df)** → Shows how many valid, LLM-ready comments are available\n",
        "\n",
        "**head(5)** → Displays sample raw comments to verify that meaning and emotion are preserved"
      ],
      "metadata": {
        "id": "2ICZUX0HjUv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_text(text):\n",
        "    \"\"\"\n",
        "    Only remove truly broken rows.\n",
        "    Preserve all real language, emojis, links, slang.\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return False\n",
        "    if text.strip() == \"\":\n",
        "        return False\n",
        "    return True\n",
        "\n"
      ],
      "metadata": {
        "id": "t6EDjbF5WfqH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function removes only invalid or empty rows while keeping all meaningful user-generated content intact, ensuring the LLM receives authentic, emotion-rich YouTube comments.\n",
        "\n",
        "**validate_text()** → Removes broken and empty entries while preserving emojis, links, slang, and real language for LLM-ready text input."
      ],
      "metadata": {
        "id": "ms_07JFNHMqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix random seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# Use ALL comments (do not randomly sample)\n",
        "comments = df[COMMENT_COLUMN].tolist()\n",
        "\n",
        "# Keep only valid LLM-safe comments\n",
        "comments = [c for c in comments if validate_text(c)]\n",
        "\n",
        "# Randomly sample a small but representative subset for experiments\n",
        "random.shuffle(comments)\n",
        "comments = comments[:300]\n",
        "print(\"Using comments for experiments:\", len(comments))\n",
        "\n",
        "\n",
        "\n",
        "print(\"Total comments used for LLM:\", len(comments))\n",
        "print(\"\\nFirst 10 comments:\")\n",
        "for c in comments[:10]:\n",
        "    print(\"-\", c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuvwBg5OWRlQ",
        "outputId": "d1abb350-b3f8-42ec-fe81-8365fb25bd35",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using comments for experiments: 300\n",
            "Total comments used for LLM: 300\n",
            "\n",
            "First 10 comments:\n",
            "- Bhaiya sorry to say but jab aap iit Kharagpur ka naam lete ho thodi si jal jati ha😅\n",
            "- Sir youtube par ai ml ka full coes lalo na\n",
            "- harry bhiya .. machine learning sikhne ke liye apke computer ki  minimum specification kya hona chaiye ?\n",
            "- Please make a sigma ai/ml course on youtube\n",
            "- So true.\n",
            "- Just 12th passed should I do it?\n",
            "- From Pakistan Learned Alot Of Python From Harry Bhai\n",
            "Alots of Love from Pakistan>>>>>>❤❤❤❤\n",
            "- Bhayiya mai robotic and automation ka student hu kya ap us pr bhi ek video bna skte hai kee kon kon see skills sikhne kee jrurat hai. Please bhayiya❤\n",
            "- Free data science course playlist full plzzz\n",
            "- Is anyone can tell me please I'm a mechanical engineer soo can I start my career in different domain as a fresher?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Comment Sampling**\n",
        "**random.seed(42)** → Ensures the same random comments are selected every time for reproducible experiments\n",
        "\n",
        "**COMMENT_COLUMN.tolist(**) → Converts the selected comments into a Python list for model input\n",
        "\n",
        "**len(comments)** → Confirms how many comments were successfully sampled\n",
        "\n",
        "**comments[:10]** → Displays a few random samples to verify correct selection"
      ],
      "metadata": {
        "id": "WCweSKwx4Xap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use RAW comments (no cleaning)\n",
        "lengths = [len(c.split()) for c in comments]\n",
        "\n",
        "print(\"Average raw comment length:\", np.mean(lengths))\n",
        "print(\"Max raw comment length:\", np.max(lengths))\n",
        "print(\"Min raw comment length:\", np.min(lengths))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTZt5SWOWmS_",
        "outputId": "c0eca1b4-1d5b-4555-c4a2-54dc7f26b758"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average raw comment length: 18.576666666666668\n",
            "Max raw comment length: 351\n",
            "Min raw comment length: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Raw Text Statistics**\n",
        "**len(c.split())** → Measures the word length of raw YouTube comments to understand their size and complexity before LLM processing."
      ],
      "metadata": {
        "id": "UNLB2JdSCHaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_comments(comments, batch_size):\n",
        "    return [comments[i:i+batch_size] for i in range(0, len(comments), batch_size)]\n",
        "\n",
        "batch_sizes = [100, 200, 300]\n",
        "\n",
        "all_batches = {}\n",
        "\n",
        "for bs in batch_sizes:\n",
        "    batches = batch_comments(comments, batch_size=bs)\n",
        "    all_batches[bs] = batches\n",
        "\n",
        "    print(f\"\\nBatch size = {bs}\")\n",
        "    print(\"Total batches:\", len(batches))\n",
        "    print(\"First batch size:\", len(batches[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMc5-qNYW7nn",
        "outputId": "48dd900f-bc23-4c73-8b92-fe448d0d33d8",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch size = 100\n",
            "Total batches: 3\n",
            "First batch size: 100\n",
            "\n",
            "Batch size = 200\n",
            "Total batches: 2\n",
            "First batch size: 200\n",
            "\n",
            "Batch size = 300\n",
            "Total batches: 1\n",
            "First batch size: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Multi-Batch Experiment**\n",
        "\n",
        "This step tests multiple batch sizes to find how many comments the LLM should see at once for the best insight quality.\n",
        "\n",
        "**batch_comments()** → Splits YouTube comments into different chunk sizes (100, 300, 600, 1000) to optimize LLM context and summarization performance"
      ],
      "metadata": {
        "id": "Agce6InNH1ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from llama_index.llms.groq import Groq\n",
        "from llama_index.core import Settings\n",
        "\n",
        "# Get Groq API key from Colab Secrets\n",
        "GROQ_API_KEY = userdata.get(\"GROQ_API_KEY\")\n",
        "\n",
        "# Configure Groq as the LLM\n",
        "Settings.llm = Groq(\n",
        "    model=\"llama-3.3-70b-versatile\",   # Use a currently supported Groq model\n",
        "    api_key=GROQ_API_KEY,\n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "print(\" Groq LLM configured successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPmixrfPinOu",
        "outputId": "949b76f2-4e90-4905-f91b-b60e1d4217c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Groq LLM configured successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LLM Configuration**\n",
        "**userdata.get(\"GROQ_API_KEY\")** → Securely retrieves the Groq API key from Colab Secrets\n",
        "\n",
        "**Groq()** → Connects LlamaIndex to Groq’s high-performance LLM platform\n",
        "\n",
        "**model=\"llama-3.3-70b-versatile\"** → Selects a powerful large language model optimized for text analysis and summarization\n",
        "\n",
        "**api_key=GROQ_API_KEY** → Authenticates requests to the Groq API\n",
        "\n",
        "**temperature=0.2** → Keeps model outputs stable, focused, and less random\n",
        "\n",
        "**Settings.llm** → Sets Groq as the global LLM engine for the entire pipeline"
      ],
      "metadata": {
        "id": "LpWZ4-Xp6aeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Document\n",
        "\n",
        "all_documents = {}\n",
        "\n",
        "for bs, batches in all_batches.items():\n",
        "    documents = []\n",
        "\n",
        "    for i, batch in enumerate(batches):\n",
        "        batch_text = \"\\n\".join(batch)\n",
        "        doc = Document(\n",
        "            text=batch_text,\n",
        "            metadata={\n",
        "                \"batch_size\": bs,\n",
        "                \"batch_id\": i + 1\n",
        "            }\n",
        "        )\n",
        "        documents.append(doc)\n",
        "\n",
        "    all_documents[bs] = documents\n",
        "    print(f\"Batch size {bs}: Created {len(documents)} documents\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0weds0nquCS",
        "outputId": "45642f42-6a78-46a4-c0fe-59ce97eeda21"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size 100: Created 3 documents\n",
            "Batch size 200: Created 2 documents\n",
            "Batch size 300: Created 1 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Multi-Batch Document Creation**\n",
        "\n",
        "This step converts each batch of YouTube comments into LLM-readable documents for every tested batch size.\n",
        "\n",
        "**Document()** → Transforms comment batches of different sizes into structured LlamaIndex documents so each chunking strategy can be evaluated independently\n"
      ],
      "metadata": {
        "id": "zeeO1su3IHed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.indices.tree import TreeIndex\n",
        "\n",
        "all_tree_indexes = {}\n",
        "\n",
        "for bs, documents in all_documents.items():\n",
        "    index = TreeIndex.from_documents(documents)\n",
        "    all_tree_indexes[bs] = index\n",
        "    print(f\"TreeIndex created for batch size {bs}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nJBro8RqxkZ",
        "outputId": "d0dfabbb-20ca-4740-8096-c5cb9df0a1b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TreeIndex created for batch size 100\n",
            "TreeIndex created for batch size 200\n",
            "TreeIndex created for batch size 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Multi-Batch Indexing**\n",
        "\n",
        "This step builds a separate TreeIndex for each batch size so different chunking strategies can be compared fairly.\n",
        "\n",
        "**TreeIndex.from_documents()** → Creates parallel knowledge trees for each batch size to evaluate which chunking strategy gives the best LLM reasoning and summaries."
      ],
      "metadata": {
        "id": "vHW1M5sK7k67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyoJ9fR6saoz",
        "outputId": "ac0cb79e-a720-4747-afce-6d3016d6d391"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Async Support**\n",
        "**nest_asyncio** → Allows multiple asynchronous event loops to run correctly inside Google Colab"
      ],
      "metadata": {
        "id": "gGxen7MN8y79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "print(\" Asyncio loop patched for Colab\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbWGuBrv2nCC",
        "outputId": "37227d0d-e47f-43ed-e191-a3f9ec700194"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Asyncio loop patched for Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Async Fix**\n",
        "**nest_asyncio.apply()** → Patches Google Colab’s event loop so LLM and LlamaIndex async operations run without errors"
      ],
      "metadata": {
        "id": "4Kkn6tVD9G1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_summaries = {}\n",
        "\n",
        "for bs, tree_index in all_tree_indexes.items():\n",
        "    query_engine = tree_index.as_query_engine(\n",
        "        response_mode=\"tree_summarize\"\n",
        "    )\n",
        "\n",
        "    prompt = \"\"\"\n",
        "    Summarize the main themes, questions, feedback, and repeated ideas\n",
        "    present in these YouTube comments. Focus on:\n",
        "    - Common questions\n",
        "    - Content requests\n",
        "    - Confusions\n",
        "    - Praise or criticism\n",
        "    \"\"\"\n",
        "\n",
        "    summary = query_engine.query(prompt)\n",
        "    all_summaries[bs] = summary\n",
        "\n",
        "    print(f\"\\n==============================\")\n",
        "    print(f\"Batch size = {bs}\")\n",
        "    print(\"==============================\")\n",
        "    print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_RGsTtxq2H6",
        "outputId": "fac12d22-5c9d-416d-dff4-8e93081023b3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "Batch size = 100\n",
            "==============================\n",
            "The main themes present in these comments include career development in AI and Machine Learning, requests for specific courses or content, and feedback on existing content. \n",
            "\n",
            "Common questions revolve around the suitability of certain courses or skills for future careers, such as MERN with generative AI, and whether non-CSE students can learn AI and ML after Python. Many users are also inquiring about the availability of courses in languages other than English, specifically Hindi.\n",
            "\n",
            "Content requests are prominent, with users asking for a roadmap for Cloud and Security, tips for getting into the field, and recommendations for books on machine learning and data mining. Some users are also requesting free access to paid courses, citing financial difficulties.\n",
            "\n",
            "Confusions arise from the suitability of certain laptops for machine learning and data analysis, and the process of enrolling in courses, particularly for international students.\n",
            "\n",
            "Praise is given for the valuable information provided, with some users appreciating the editing of the content. Criticism is also present, with some users finding the thumbnail of a video to be unappealing.\n",
            "\n",
            "Repeated ideas include the importance of learning Python and essential math skills for a career in AI and ML, and the need for a roadmap or guidance for those starting out in the field. The hashtag #harrybhai is also repeated, indicating that the comments are addressed to or about a person named Harry, likely the creator of the content. Overall, the comments reflect a desire for guidance, resources, and support in pursuing a career in AI and ML.\n",
            "\n",
            "==============================\n",
            "Batch size = 200\n",
            "==============================\n",
            "The main themes present in these comments include career development in AI and Machine Learning, requests for specific courses or content, and discussions about learning resources. \n",
            "\n",
            "Common questions revolve around the suitability of certain courses or skills for future careers, such as MERN with generative AI, and whether non-CSE students can learn AI and ML after Python. Some users also ask about the availability of courses in Hindi and the process of subscription.\n",
            "\n",
            "Content requests are prominent, with users asking for a roadmap for Cloud and Security, tips for machine learning, and recommendations for books on the subject. Some users also request Harry to create more courses, specifically in areas like game development and data analysis.\n",
            "\n",
            "Confusions arise from users who are unsure about their career paths, such as a student who wants to learn maths and another who is unsure if they can get a job without a degree. There are also questions about the suitability of certain laptops for machine learning and data analysis.\n",
            "\n",
            "Praise is evident in comments that appreciate the valuable information provided, while criticism is seen in a comment that finds a thumbnail ugly. Overall, the comments reflect a community seeking guidance and resources for learning and career development in AI, ML, and related fields. Repeated ideas include the importance of learning Python, the need for efficient learning strategies, and the desire for accessible and affordable educational resources.\n",
            "\n",
            "==============================\n",
            "Batch size = 300\n",
            "==============================\n",
            "The main themes present in these comments include career development, learning, and education in the fields of AI, ML, data science, and programming. \n",
            "\n",
            "Common questions revolve around the feasibility of learning and working in these fields without a degree, the best courses or resources for beginners, and how to get started with specific skills like Python, data analysis, and machine learning. Many users are seeking guidance on career paths, including how to crack interviews at top companies and the potential for biology students or non-CSE individuals to work in these fields.\n",
            "\n",
            "Content requests are abundant, with users asking for specific courses, such as a roadmap for Cloud & Security, a Python Django course, or a course on JavaScript basics. Some users request more information on how to deploy apps or learn data analytics. There's also a demand for courses in Hindi and for free or affordable learning resources.\n",
            "\n",
            "Confusions arise from users unsure about the best laptops for future-proofing their learning and career in fields like game development, machine learning, and data analysis. Others are confused about the enrollment process for certain courses or the availability of courses for students from different countries.\n",
            "\n",
            "Praise is a significant theme, with many users appreciating the content creator's hard work and the value they derive from the videos. Users often express gratitude for the information provided and the inspiration they get from the content. Criticism is less common but includes feedback on aesthetics, such as finding a thumbnail ugly, and requests for improvements, like providing links to resources mentioned in videos.\n",
            "\n",
            "Repeated ideas include the importance of learning Python, the potential of AI and ML for career growth, and the need for accessible, high-quality educational resources. The community seems to value practical advice, career guidance, and support in their learning journeys. Overall, the comments reflect a community eager to learn, grow, and engage with the content creator and each other.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Multi-Batch Insight Generation**\n",
        "\n",
        "This step runs the same insight-extraction prompt on each batch-size TreeIndex so we can compare how different chunk sizes affect the quality of LLM summaries.\n",
        "\n",
        "**all_tree_indexes** → Stores a separate TreeIndex for each batch size\n",
        "\n",
        "**tree_index.as_query_engine()** → Converts each TreeIndex into an LLM-powered question-answering and summarization engine\n",
        "\n",
        "**response_mode=\"tree_summarize\"** → Forces the LLM to read all batches and generate a global, hierarchical summary\n",
        "\n",
        "**prompt** → Defines exactly what creator-level insights the LLM should extract\n",
        "\n",
        "**query_engine.query(prompt)** → Runs the prompt on the full comment knowledge base for that batch size\n",
        "\n",
        "**all_summaries[bs]** → Stores the summary output for each batch size so they can be compared\n"
      ],
      "metadata": {
        "id": "woBlvQurJd-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = \"\"\"\n",
        "You are an AI assistant helping a YouTube creator.\n",
        "\n",
        "Based on these comments, generate a clear and structured insight report with:\n",
        "1. Top 5 content topics viewers want\n",
        "2. Top 5 recurring questions\n",
        "3. Main confusions or learning barriers\n",
        "4. Overall audience sentiment\n",
        "5. 3 recommended next video ideas\n",
        "\"\"\"\n",
        "prompt_P1 = \"\"\"\n",
        "You are an AI assistant helping a YouTube creator understand their audience deeply.\n",
        "\n",
        "From these YouTube comments extract:\n",
        "1. The biggest problems or struggles viewers are facing\n",
        "2. The most requested content or topics\n",
        "3. Frequently asked questions\n",
        "4. Emotional signals (confusion, excitement, frustration, praise)\n",
        "5. Opportunities for new videos, courses, or tutorials\n",
        "\n",
        "Focus on repeated and high-impact signals. Ignore spam and one-off comments.\n",
        "\"\"\"\n",
        "\n",
        "prompt_P2 = \"\"\"\n",
        "You are a YouTube growth strategist.\n",
        "\n",
        "Analyze these comments to identify:\n",
        "1. Viewer segments (beginners, intermediate, advanced)\n",
        "2. What is blocking viewers from learning or progressing\n",
        "3. Language or format preferences (Hindi, English, short videos, full courses)\n",
        "4. High-demand topics that can drive subscribers and revenue\n",
        "5. A data-driven plan for the creator’s next 3 videos\n",
        "\n",
        "Give actionable insights that a YouTuber can use to grow their channel.\n",
        "\"\"\"\n",
        "\n",
        "prompts = {\n",
        "    \"P0_Baseline\": final_prompt,\n",
        "    \"P1_Creator_Intelligence\": prompt_P1,\n",
        "    \"P2_Growth_Strategy\": prompt_P2\n",
        "}\n",
        "\n",
        "all_final_reports = {}\n",
        "\n",
        "for bs, tree_index in all_tree_indexes.items():\n",
        "    query_engine = tree_index.as_query_engine(response_mode=\"tree_summarize\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Batch size = {bs}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    all_final_reports[bs] = {}\n",
        "\n",
        "    for name, prompt in prompts.items():\n",
        "        result = query_engine.query(prompt)\n",
        "        all_final_reports[bs][name] = result\n",
        "\n",
        "        print(f\"\\n--- {name} ---\\n\")\n",
        "        print(result)\n",
        "\n"
      ],
      "metadata": {
        "id": "P86a3LzKtgUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378e4a47-9499-4352-d8e4-7339def34c8a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Batch size = 100\n",
            "==================================================\n",
            "\n",
            "--- P0_Baseline ---\n",
            "\n",
            "Insight Report:\n",
            "\n",
            "**1. Top 5 Content Topics Viewers Want:**\n",
            "1. AI and Machine Learning (ML) courses and tutorials\n",
            "2. Data Science and related topics\n",
            "3. Python programming and its applications (e.g., Django)\n",
            "4. Cybersecurity courses\n",
            "5. Android development and software engineering\n",
            "\n",
            "**2. Top 5 Recurring Questions:**\n",
            "1. What are the minimum computer specifications required for learning ML?\n",
            "2. Can a non-technical person or someone from a different domain (e.g., mechanical engineering) start a career in AI/ML or software engineering?\n",
            "3. What is the duration of AI and ML courses?\n",
            "4. How to get started with coding and web development?\n",
            "5. What are the skills required for robotic and automation?\n",
            "\n",
            "**3. Main Confusions or Learning Barriers:**\n",
            "- Confusion between AI and Data Science\n",
            "- Difficulty in choosing the right career path (e.g., JEE, NEET, or coding)\n",
            "- Technical issues (e.g., accessing purchased courses due to incorrect email)\n",
            "- Lack of clear guidance on how to start learning coding and AI/ML\n",
            "- High GST on courses (18%) is seen as a barrier\n",
            "\n",
            "**4. Overall Audience Sentiment:**\n",
            "The overall audience sentiment is positive, with viewers expressing gratitude and appreciation for the creator's content. Many viewers have found the creator's videos helpful in learning new skills and gaining confidence in their career choices. However, some viewers have raised concerns about technical issues, course accessibility, and high GST rates.\n",
            "\n",
            "**5. 3 Recommended Next Video Ideas:**\n",
            "1. **AI/ML Full Roadmap and Playlist**: Create a comprehensive video that outlines the entire roadmap for learning AI and ML, including resources, tutorials, and project ideas.\n",
            "2. **Database SQL and Oracle Tutorial**: Produce a tutorial series on Database SQL and Oracle, covering the basics and advanced topics, to cater to the demand for database-related content.\n",
            "3. **Roadmap to Software Engineering in 2025**: Develop a video that provides a clear roadmap for software engineering, including the necessary skills, courses, and career paths, to help viewers navigate this field effectively.\n",
            "\n",
            "--- P1_Creator_Intelligence ---\n",
            "\n",
            "After analyzing the YouTube comments, I've extracted the following insights:\n",
            "\n",
            "**1. Biggest problems or struggles viewers are facing:**\n",
            "- Difficulty in choosing a specialization (AI/ML or other fields)\n",
            "- Struggling to learn and implement AI and ML concepts\n",
            "- Limited knowledge of Python and its application in machine learning\n",
            "- Concerns about the relevance of their current field of study (e.g., BCA, MERN stack) in the AI era\n",
            "- Difficulty in understanding specific concepts like feature engineering, SQL, and data science\n",
            "\n",
            "**2. Most requested content or topics:**\n",
            "- AI and ML courses or tutorials\n",
            "- Data science and data analytics content\n",
            "- Game development roadmap\n",
            "- Android development course\n",
            "- Setup tutorials (e.g., PC specs requirements)\n",
            "- Data breaches and security-related topics\n",
            "- GSOC (Google Summer of Code) video\n",
            "- Feature engineering and its importance in machine learning\n",
            "\n",
            "**3. Frequently asked questions:**\n",
            "- How much Python should I learn to get into machine learning?\n",
            "- Should I choose AI/ML specialization or other fields?\n",
            "- Can I buy your course, and is it job-ready?\n",
            "- Are your courses available in Hindi?\n",
            "\n",
            "**4. Emotional signals:**\n",
            "- Excitement and praise for the creator's content (e.g., \"Love you Harry bhaiya\", \"Legendary\", \"Amazing work!\")\n",
            "- Frustration and confusion about specific concepts (e.g., \"why are you rushing so much and missing important topics?\")\n",
            "- Appreciation for the creator's teaching style (e.g., \"You teach better than apna college\")\n",
            "\n",
            "**5. Opportunities for new videos, courses, or tutorials:**\n",
            "- Creating a comprehensive AI/ML course with a focus on feature engineering and data science\n",
            "- Developing a game development roadmap tutorial\n",
            "- Producing a video on data breaches and security best practices\n",
            "- Offering a setup tutorial for PC specs requirements\n",
            "- Creating a GSOC video or tutorial\n",
            "- Developing an Android development course\n",
            "- Providing more content on data analytics and machine learning for arts stream students\n",
            "- Offering courses or tutorials in Hindi to cater to a broader audience\n",
            "\n",
            "These insights can help the YouTube creator understand their audience's needs, preferences, and pain points, enabling them to create more relevant and engaging content.\n",
            "\n",
            "--- P2_Growth_Strategy ---\n",
            "\n",
            "Analyzing the comments, we can identify the following insights:\n",
            "\n",
            "1. **Viewer segments**: The audience consists of beginners (e.g., \"Bhai mai 12th me hun aur maine CS ko liya hai\", \"Brother I'm learning MERN with generative AI\"), intermediate learners (e.g., \"I already am doing like 60% of this is crazy I just wanna learn maths now lmao\"), and advanced viewers (e.g., \"How to crack hft companies\"). This suggests that the creator's content is appealing to a broad range of learners.\n",
            "\n",
            "2. **Blocks to learning or progressing**: Viewers are facing obstacles such as lack of resources (e.g., \"bhai free kardo yaar garib hu\"), uncertainty about career paths (e.g., \"Kya Ham NON CSE WALLE BHI SIKH sakte he AI ML AFTER PYTHON\"), and difficulty in finding relevant learning materials (e.g., \"Complete roadmap\"). Some viewers are also seeking guidance on how to get started with AI and ML (e.g., \"Start learning AI with Python and essential math skills\").\n",
            "\n",
            "3. **Language or format preferences**: There is a clear demand for Hindi content (e.g., \"Ye paid course hindi me hai sir @codewithharry\", \"bhai ye thumbnail bahut ugly lg rha h, first wala hi thik tha\" which is written in Hindi). Viewers also appreciate short, informative videos (e.g., \"nice editing :)\"), and some are interested in full courses (e.g., \"Vote For Ai & ML Course\").\n",
            "\n",
            "4. **High-demand topics**: The comments suggest that viewers are interested in AI, ML, data science, and machine learning (e.g., \"Learn Data Science for a career in AI and Machine Learning\", \"Roadmap for Cloud & Security\"). Other in-demand topics include game development, data analysis, and career guidance (e.g., \"How to crack hft companies\", \"Kya ye course aiml ke students ke liye hai\").\n",
            "\n",
            "5. **Data-driven plan for the next 3 videos**:\n",
            "    * **Video 1**: \"Getting Started with AI and ML for Beginners\" - This video can provide an introduction to AI and ML, covering the basics of Python, essential math skills, and key libraries for data analysis. The video can be created in Hindi to cater to the demand for regional content.\n",
            "    * **Video 2**: \"Career Paths in Data Science and Machine Learning\" - This video can focus on the various career opportunities available in data science and machine learning, including job roles, required skills, and industry trends. The video can include interviews with industry experts or showcase success stories of professionals in the field.\n",
            "    * **Video 3**: \"Building a Project with MERN and Generative AI\" - This video can provide a hands-on tutorial on building a project using MERN (MongoDB, Express, React, Node.js) and generative AI. The video can cater to intermediate learners and provide a step-by-step guide on how to integrate AI and ML into web development projects.\n",
            "\n",
            "Actionable insights for the YouTuber:\n",
            "\n",
            "* Create content that caters to a broad range of learners, from beginners to advanced viewers.\n",
            "* Offer free or affordable resources to help viewers overcome financial barriers.\n",
            "* Provide career guidance and showcase success stories to motivate viewers.\n",
            "* Create content in Hindi to cater to the demand for regional content.\n",
            "* Focus on high-demand topics such as AI, ML, data science, and machine learning.\n",
            "* Collaborate with industry experts or other creators to provide diverse perspectives and insights.\n",
            "* Use engaging formats such as tutorials, interviews, and success stories to keep viewers engaged.\n",
            "\n",
            "==================================================\n",
            "Batch size = 200\n",
            "==================================================\n",
            "\n",
            "--- P0_Baseline ---\n",
            "\n",
            "**Insight Report**\n",
            "\n",
            "### 1. Top 5 Content Topics Viewers Want\n",
            "1. **Machine Learning and AI**: Viewers are interested in learning about machine learning, AI, and their applications.\n",
            "2. **Data Science and Python**: There is a demand for content on data science, Python programming, and its relevance to machine learning and AI.\n",
            "3. **Career Development and Roadmaps**: Viewers are seeking guidance on career paths, roadmaps for learning, and how to get started in the field of AI and ML.\n",
            "4. **Cloud and Security**: Some viewers have expressed interest in learning about cloud computing and security, particularly in relation to AI and ML.\n",
            "5. **MERN and Generative AI**: A few viewers are interested in learning about MERN (MongoDB, Express, React, Node) and generative AI.\n",
            "\n",
            "### 2. Top 5 Recurring Questions\n",
            "1. **How to get started with AI and ML**: Many viewers are asking for advice on how to begin their journey in AI and ML.\n",
            "2. **Career prospects and job opportunities**: Viewers want to know about the career prospects and job opportunities available in the field of AI and ML.\n",
            "3. **Learning resources and recommendations**: Viewers are seeking recommendations for books, courses, and other learning resources.\n",
            "4. **Eligibility and prerequisites**: Some viewers are unsure about the prerequisites for learning AI and ML, such as whether a degree is required.\n",
            "5. **Access to courses and subscriptions**: Viewers are asking about how to access courses, particularly those that are paid or subscription-based.\n",
            "\n",
            "### 3. Main Confusions or Learning Barriers\n",
            "1. **Lack of clarity on getting started**: Many viewers are unsure about how to begin their journey in AI and ML.\n",
            "2. **Confusion about prerequisites**: Some viewers are confused about the prerequisites for learning AI and ML, such as whether a degree is required.\n",
            "3. **Limited access to resources**: Viewers may face barriers in accessing courses, books, or other learning resources due to financial constraints or geographical location.\n",
            "4. **Uncertainty about career prospects**: Viewers are uncertain about the career prospects and job opportunities available in the field of AI and ML.\n",
            "\n",
            "### 4. Overall Audience Sentiment\n",
            "The overall audience sentiment is positive, with many viewers expressing gratitude for the valuable information and resources provided. However, some viewers are facing challenges and uncertainties, which is reflected in their questions and comments.\n",
            "\n",
            "### 5. 3 Recommended Next Video Ideas\n",
            "1. **\"A Beginner's Guide to Getting Started with AI and ML\"**: A video that provides a step-by-step guide for beginners, covering the basics of AI and ML, and how to get started.\n",
            "2. **\"Career Roadmap for AI and ML: Opportunities and Prospects\"**: A video that explores the career prospects and job opportunities available in the field of AI and ML, and provides guidance on how to create a career roadmap.\n",
            "3. **\"Overcoming Learning Barriers: Tips and Resources for AI and ML\"**: A video that addresses the common learning barriers and challenges faced by viewers, and provides tips and resources for overcoming them, including recommendations for books, courses, and other learning resources.\n",
            "\n",
            "--- P1_Creator_Intelligence ---\n",
            "\n",
            "After analyzing the YouTube comments, here are the extracted insights:\n",
            "\n",
            "1. **Biggest problems or struggles viewers are facing:**\n",
            "\t* Lack of guidance on getting started with AI and ML (e.g., \"Kya Ham NON CSE WALLE BHI SIKH sakte he AI ML AFTER PYTHON\")\n",
            "\t* Difficulty in choosing the right resources and courses (e.g., \"Bhai ye thumbnail bahut ugly lg rha h, first wala hi thik tha\" implies they are looking for quality content)\n",
            "\t* Financial constraints (e.g., \"bhai free kardo yaar garib hu\")\n",
            "\t* Career uncertainty and job replacement concerns (e.g., \"AI will replace jobs, but degrees still matter\")\n",
            "2. **Most requested content or topics:**\n",
            "\t* Roadmap for Cloud and Security (e.g., \"Hi Harry Sir, hope you are doing well! I have request if could we have a Roadmap for Cloud & Security?\")\n",
            "\t* Machine Learning and Data Science (e.g., \"Learn Data Science for a career in AI and Machine Learning\")\n",
            "\t* Python programming and essential math skills (e.g., \"Start learning AI with Python and essential math skills\")\n",
            "\t* Game development and data analysis (e.g., \"mijhe game dev. And machine learning / data analysis karna hai\")\n",
            "3. **Frequently asked questions:**\n",
            "\t* Can non-CSE students learn AI and ML? (e.g., \"Kya Ham NON CSE WALLE BHI SIKH sakte he AI ML AFTER PYTHON\")\n",
            "\t* How to get started with AI and ML? (e.g., \"Start learning AI with Python and essential math skills\")\n",
            "\t* What are the best resources and courses for AI and ML? (e.g., \"Learn Python basics and key libraries for data analysis\")\n",
            "4. **Emotional signals:**\n",
            "\t* Excitement and enthusiasm (e.g., \"nice editing :)\", \"thanks for valuable info)\")\n",
            "\t* Frustration and desperation (e.g., \"bhai free kardo yaar garib hu\")\n",
            "\t* Confusion and uncertainty (e.g., \"Kya ye course aiml ke students ke liye hai?\")\n",
            "\t* Appreciation and praise (e.g., \"thanx harry bhai for this!!\")\n",
            "5. **Opportunities for new videos, courses, or tutorials:**\n",
            "\t* Creating a comprehensive roadmap for Cloud and Security\n",
            "\t* Developing a beginner-friendly course on Machine Learning and Data Science\n",
            "\t* Producing tutorials on Python programming and essential math skills\n",
            "\t* Collaborating with other creators to provide free or low-cost resources for students with financial constraints\n",
            "\t* Creating content on game development and data analysis\n",
            "\t* Hosting Q&A sessions or live streams to address viewer questions and concerns\n",
            "\n",
            "--- P2_Growth_Strategy ---\n",
            "\n",
            "Analyzing the comments, we can identify the following insights:\n",
            "\n",
            "1. **Viewer segments**: The audience consists of beginners (e.g., \"Bhai mai 12th me hun aur maine CS ko liya hai\"), intermediate learners (e.g., \"Brother I'm learning MERN with generative AI\"), and advanced viewers (e.g., \"I already am doing like 60% of this is crazy I just wanna learn maths now lmao\"). This suggests that the creator's content appeals to a broad range of audiences.\n",
            "\n",
            "2. **Blocking factors**: Viewers are facing obstacles such as lack of resources (e.g., \"bhai free kardo yaar garib hu\"), uncertainty about career paths (e.g., \"Kya Ham NON CSE WALLE BHI SIKH sakte he AI ML AFTER PYTHON\"), and difficulty in understanding complex topics (e.g., \"Bhai ye thumbnail bahut ugly lg rha h, first wala hi thik tha\" - although this is not directly related to learning, it indicates a need for better visual explanations). Additionally, some viewers are struggling to access the content due to geographical constraints (e.g., \"Harry bhi I from Pakistan I want the subscription of your Al and ML course how I do it\").\n",
            "\n",
            "3. **Language and format preferences**: There is a clear demand for Hindi content (e.g., \"Ye paid course hindi me hai sir @codewithharry\", \"bhai free kardo yaar garib hu\" - which is written in a mix of Hindi and English). Viewers also appreciate short, concise videos (e.g., \"nice editing :)\"), and some are interested in full courses (e.g., \"Complete roadmap\").\n",
            "\n",
            "4. **High-demand topics**: The comments suggest a strong interest in AI, ML, and data science (e.g., \"Vote For Ai & ML Course\", \"Learn Data Science for a career in AI and Machine Learning\"). Other in-demand topics include cloud and security (e.g., \"Bhai ye roadmap for Cloud & Security\"), game development (e.g., \"game dev. And machine learning / data analysis karna hai\"), and mathematics for AI and ML (e.g., \"Focus on efficient learning in mathematics for AI and ML\").\n",
            "\n",
            "5. **Data-driven plan for the next 3 videos**:\n",
            "   - **Video 1**: Create a beginner-friendly video on \"Introduction to AI and ML with Python\" in Hindi, focusing on the basics and providing a roadmap for further learning. This will cater to the large number of beginner viewers and address the demand for Hindi content.\n",
            "   - **Video 2**: Produce a video on \"Cloud and Security for AI and ML\" in English, targeting intermediate and advanced viewers. This will help establish the creator as an authority in the field and attract viewers interested in more specialized topics.\n",
            "   - **Video 3**: Develop a video on \"Mathematics for AI and ML\" in a short, concise format, using engaging visuals and examples. This will help viewers who are struggling with mathematical concepts and provide a valuable resource for those looking to improve their skills.\n",
            "\n",
            "Actionable insights for the YouTuber:\n",
            "\n",
            "* Offer a mix of free and paid content to cater to viewers with different financial backgrounds.\n",
            "* Provide subtitles or translations for videos to make them more accessible to a broader audience.\n",
            "* Create a community or forum for viewers to discuss topics, ask questions, and share their progress.\n",
            "* Collaborate with other creators or experts in the field to produce high-quality, engaging content.\n",
            "* Utilize social media platforms to promote the channel, share behind-the-scenes content, and interact with viewers.\n",
            "\n",
            "==================================================\n",
            "Batch size = 300\n",
            "==================================================\n",
            "\n",
            "--- P0_Baseline ---\n",
            "\n",
            "Insight Report:\n",
            "\n",
            "**1. Top 5 Content Topics Viewers Want:**\n",
            "1. AI and Machine Learning (ML) courses and tutorials\n",
            "2. Data Science and related topics\n",
            "3. Python programming and its applications\n",
            "4. Cybersecurity courses and tutorials\n",
            "5. Android development and software engineering\n",
            "\n",
            "**2. Top 5 Recurring Questions:**\n",
            "1. What are the minimum system requirements for learning ML and AI?\n",
            "2. Can non-technical individuals learn coding and AI/ML?\n",
            "3. What is the duration of AI and ML courses?\n",
            "4. How to get started with website development and where to learn?\n",
            "5. What are the differences between AI, ML, and Data Science?\n",
            "\n",
            "**3. Main Confusions or Learning Barriers:**\n",
            "1. Confusion between AI, ML, and Data Science\n",
            "2. Difficulty in choosing the right course or career path (e.g., IIT, NEET, coding)\n",
            "3. Limited access to resources and guidance for non-technical individuals\n",
            "4. Uncertainty about system requirements for learning AI and ML\n",
            "5. Difficulty in understanding the scope and applications of AI and ML\n",
            "\n",
            "**4. Overall Audience Sentiment:**\n",
            "The overall audience sentiment is positive, with viewers appreciating the creator's teaching style and content. Many viewers have expressed gratitude for the creator's guidance and encouragement, which has helped them learn new skills and gain confidence. However, some viewers have also expressed frustration with technical issues, such as audio quality, and have requested more content on specific topics.\n",
            "\n",
            "**5. 3 Recommended Next Video Ideas:**\n",
            "1. \"AI and ML Roadmap for Beginners\" - a video that provides a clear and structured roadmap for learning AI and ML, including recommended courses, resources, and projects.\n",
            "2. \"Overcoming Common Barriers in Learning AI and ML\" - a video that addresses common learning barriers, such as limited access to resources, and provides guidance on how to overcome them.\n",
            "3. \"Career Paths in AI and ML: Opportunities and Challenges\" - a video that explores the various career paths available in AI and ML, including job roles, salary expectations, and required skills, to help viewers make informed decisions about their career choices.\n",
            "\n",
            "--- P1_Creator_Intelligence ---\n",
            "\n",
            "After analyzing the YouTube comments, I've extracted the following insights to help the creator understand their audience deeply:\n",
            "\n",
            "**1. Biggest problems or struggles viewers are facing:**\n",
            "- Difficulty in choosing a career path or course (e.g., data science, AI, ML, or web development)\n",
            "- Lack of mathematical background or weak math skills, making it hard to learn AI and ML\n",
            "- Confusion about which programming language or technology to learn (e.g., Python, Java, HTML, CSS)\n",
            "- Financial constraints, with some viewers finding courses too expensive\n",
            "- Struggling to learn programming concepts, such as data structures and algorithms\n",
            "\n",
            "**2. Most requested content or topics:**\n",
            "- Data science and machine learning courses or tutorials\n",
            "- AI and ML for beginners, especially for those with weak math backgrounds\n",
            "- Web development (including HTML, CSS, and JavaScript)\n",
            "- Python programming and its applications\n",
            "- Data analytics and related tools like NumPy and Pandas\n",
            "\n",
            "**3. Frequently asked questions:**\n",
            "- What courses or fields should I choose for a career in AI, ML, or data science?\n",
            "- How can I learn AI and ML with a weak math background?\n",
            "- What are the best resources (courses, tutorials, or books) for learning specific technologies or programming languages?\n",
            "- Are certain courses or certifications worth the investment?\n",
            "\n",
            "**4. Emotional signals:**\n",
            "- **Confusion**: Viewers are uncertain about their career paths or how to learn specific technologies.\n",
            "- **Excitement**: Some viewers are enthusiastic about learning new technologies and starting their careers in AI, ML, or web development.\n",
            "- **Frustration**: Financial constraints and difficulty in learning certain concepts are causing frustration among viewers.\n",
            "- **Praise**: The creator is appreciated for their content, and viewers are expressing gratitude for the help they've received.\n",
            "\n",
            "**5. Opportunities for new videos, courses, or tutorials:**\n",
            "- Create a beginner's series on AI and ML, focusing on building a strong mathematical foundation.\n",
            "- Develop a course or tutorial on web development using HTML, CSS, and JavaScript.\n",
            "- Produce content on data analytics, including tutorials on NumPy and Pandas.\n",
            "- Offer guidance on choosing a career path in tech, including advice on selecting the right courses or fields.\n",
            "- Collaborate with other creators or industry experts to provide diverse perspectives and insights.\n",
            "- Consider creating content in multiple languages, including Hindi, to cater to a broader audience.\n",
            "\n",
            "--- P2_Growth_Strategy ---\n",
            "\n",
            "Analyzing the comments, we can identify the following insights:\n",
            "\n",
            "**1. Viewer segments:**\n",
            "- Beginners: Many viewers are new to AI, ML, and data science, asking for basic courses and resources (e.g., \"Kya Ham NON CSE WALLE BHI SIKH sakte he AI ML AFTER PYTHON\", \"Learn Data Science for a career in AI and Machine Learning\").\n",
            "- Intermediate: Some viewers are looking to improve their skills in specific areas, such as machine learning, data analysis, and web development (e.g., \"Brother I'm learning MERN with generative AI will it be good for future please reply\", \"Sir Please do reply I got coursera free liscence for 6 months I want to do data analytics\").\n",
            "- Advanced: A few viewers are seeking more specialized knowledge, like deploying apps or working with specific technologies (e.g., \"Bhai i am create app in replit but i don't no how to deploy\", \"ASUS ROG G16 G614JV-N4242WS lene wala hu i9 13th gen, rtx4060 ke saath\").\n",
            "\n",
            "**2. Blocking factors:**\n",
            "- Lack of resources (e.g., \"bhai free kardo yaar garib hu\", \"I have no degree nor I have money to get one can I too get go job if I develop my skills\").\n",
            "- Limited access to information (e.g., \"Queen marry wale notes ka link discription mai nhi hai bhaiya\").\n",
            "- Difficulty in understanding complex concepts (e.g., \"Start learning AI with Python and essential math skills\", \"Focus on efficient learning in mathematics for AI and ML\").\n",
            "\n",
            "**3. Language and format preferences:**\n",
            "- Hindi: Many viewers prefer Hindi content (e.g., \"Ye paid course hindi me hai sir @codewithharry\", \"sir ap ki har video dekh ta hu ap ki sab video buhat achi hoti ha\").\n",
            "- English: Some viewers are comfortable with English content (e.g., \"Thanks for valuable info)\", \"First comment, Harry Buddy you're content always great, appreciate your every single hard working\").\n",
            "- Short videos and full courses: Viewers are interested in both short, informative videos and comprehensive courses (e.g., \"nice editing :)\", \"Python Django Course\").\n",
            "\n",
            "**4. High-demand topics:**\n",
            "- AI and ML: These topics are consistently mentioned throughout the comments (e.g., \"Vote For Ai & ML Course\", \"Brother I'm learning MERN with generative AI will it be good for future please reply\").\n",
            "- Data science and analytics: Viewers are interested in learning data science and analytics (e.g., \"Learn Data Science for a career in AI and Machine Learning\", \"Sir Please do reply I got coursera free liscence for 6 months I want to do data analytics\").\n",
            "- Web development: Some viewers are interested in web development, particularly with Python and Django (e.g., \"Sigma Web Development OP \", \"Bhai i am create app in replit but i don't no how to deploy\").\n",
            "\n",
            "**5. Data-driven plan for the next 3 videos:**\n",
            "Based on the analysis, the creator's next three videos could be:\n",
            "1. **\"Introduction to AI and ML with Python\"**: A beginner-friendly video that covers the basics of AI and ML using Python, addressing the demand for introductory content.\n",
            "2. **\"Data Science and Analytics for Beginners\"**: A video that provides an overview of data science and analytics, including the necessary skills and resources for beginners, catering to the interest in data science.\n",
            "3. **\"Deploying Apps with Replit and Python\"**: A tutorial-style video that guides viewers through the process of deploying apps using Replit and Python, addressing the specific question from a viewer and providing valuable information for intermediate learners.\n",
            "\n",
            "By creating content that addresses the needs and interests of the viewers, the creator can increase engagement, attract new subscribers, and drive revenue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prompt & Chunking Optimization**\n",
        "\n",
        "This step runs multiple prompt strategies on each batch-size TreeIndex to compare how different prompts and chunk sizes affect the quality, depth, and usefulness of YouTube creator insights.\n",
        "\n",
        "**final_prompt** → Baseline prompt for generating standard creator insights\n",
        "\n",
        "**prompt_P1** → Creator-intelligence prompt focused on viewer pain points, emotions, and content demand\n",
        "\n",
        "**prompt_P2** → Growth-strategy prompt focused on audience segments, monetization, and channel expansion\n",
        "\n",
        "**prompts{}** → Stores multiple prompt versions for systematic comparison\n",
        "\n",
        "**all_tree_indexes** → Provides different TreeIndexes built using different batch sizes\n",
        "\n",
        "**tree_index.as_query_engine()** → Converts each TreeIndex into an LLM-powered reasoning and summarization engine\n",
        "\n",
        "**response_mode=\"tree_summarize\"** → Forces the LLM to analyze all comment chunks and produce a global structured report\n",
        "\n",
        "**query_engine.query(prompt)** → Runs each prompt on the full YouTube comment knowledge base\n",
        "\n",
        "**all_final_reports[bs][name]** → Stores every output by batch size and prompt type for evaluation\n",
        "\n",
        "**print(result)** → Displays the generated creator-ready intelligence reports"
      ],
      "metadata": {
        "id": "s9Jyjl3LKU02"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ox3dX-JbK8lx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
